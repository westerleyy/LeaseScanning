{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82ee09ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path, convert_from_bytes\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pytesseract import Output\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "from huggingface_hub import hf_hub_download\n",
    "from transformers import AutoConfig, AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "\n",
    "# set directories for PyTesseract, Poppler, and script\n",
    "poppler_path = r'C:\\Users\\<INSERT_USER_ID>\\anaconda3\\Lib\\poppler-22.04.0\\Library\\bin'\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "folder_path = r'C:\\Users\\<FOLDER_PATH>'\n",
    "os.chdir(folder_path)\n",
    "\n",
    "## get list of pdf files\n",
    "pdf_files = os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5208f453",
   "metadata": {},
   "source": [
    "Steps to follow: \n",
    "1) Determine if record is PDF or TIFF  \n",
    "2) Convert PDF records to images  \n",
    "3) Improve image quality  \n",
    "4) Extract text from the image  \n",
    "5) Step through every single page in the record  \n",
    "6) Extract the required paragraph based on the list of trigger phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3cad9a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dp_dc_extraction(file_path, pass_one = True, poppler_path = poppler_path):\n",
    "    def rotation(angle, width_center, height_center, width, height, invert):\n",
    "        M = cv2.getRotationMatrix2D((width_center, height_center), angle, 1)\n",
    "        invert = cv2.warpAffine(invert, M, (height, width), borderMode=cv2.BORDER_REPLICATE)\n",
    "        return invert\n",
    "\n",
    "    def rotation_determination(invert):\n",
    "\n",
    "        try: \n",
    "            rotation_results = pytesseract.image_to_osd(invert, output_type = pytesseract.Output.DICT)   \n",
    "\n",
    "            if rotation_results[\"orientation\"] == 270:\n",
    "                invert = rotation(angle = rotation_results[\"orientation\"],\n",
    "                                  width_center = width/3, height_center = height/2,\n",
    "                                  width = width, height = height, invert = invert)\n",
    "\n",
    "            elif rotation_results[\"orientation\"] == 90:\n",
    "                invert = rotation(angle = rotation_results[\"orientation\"],\n",
    "                                  width_center = width/2, height_center = height/2,\n",
    "                                  width = width, height = height, invert = invert)\n",
    "\n",
    "            elif rotation_results[\"orientation\"] == 180:\n",
    "                invert = rotation(angle = rotation_results[\"orientation\"],\n",
    "                                  width_center = width/2, height_center = height/2,\n",
    "                                  width = width, height = height, invert = invert)\n",
    "            #else:\n",
    "            #    invert = invert\n",
    "\n",
    "            blank_page_indicator = \"N\"\n",
    "            return invert, blank_page_indicator\n",
    "\n",
    "        except:\n",
    "            # print (\"Blank Page\")\n",
    "            blank_page_indicator = \"Y\"\n",
    "            return \"Blank Page\", blank_page_indicator\n",
    "    \n",
    "    def clause_shortener(x):\n",
    "        clause_splits = [r\"We wish to inform you\", r\"Please note that\"]\n",
    "        clause_subs = [\"<INSERT_PHRASES>\"]\n",
    "        \n",
    "        for split in clause_splits:\n",
    "            x = re.split(pattern = split, string = x)[0]\n",
    "        for sub in clause_subs:\n",
    "            x = re.sub(sub, \"\", string = x)\n",
    "        \n",
    "        x = x.rstrip()\n",
    "        x = x.lstrip()\n",
    "        return x\n",
    "    \n",
    "    # indicators that show where the relevant clauses might be\n",
    "    if pass_one == True:\n",
    "        opening_phrases = [\"<INSERT_PHRASES>\"]\n",
    "    else:\n",
    "        opening_phrases = [\"<INSERT_PHRASES>\"]\n",
    "    closing_phrases = [\"<INSERT_PHRASES>\"]\n",
    "    unwanted_characters = ['\\n', '-', '—', ';', ':', '{', '}', '~', '?', '_', '‘', '@', '%', '|']\n",
    "    months_of_year = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October',\n",
    "                     'November', 'December']\n",
    "    \n",
    "    record_path = file_path\n",
    "    #if record_path.split('.')[1] == '.tif':\n",
    "    pages_images = convert_from_path(record_path, poppler_path = poppler_path)\n",
    "    \n",
    "    pages_tesseract = []\n",
    "\n",
    "    for i in range(len(pages_images)):\n",
    "        if i == 0 & pass_one == True:\n",
    "            continue\n",
    "        else:\n",
    "            blank_page_indicator = \"N\"\n",
    "            height, width = np.asarray(pages_images[i]).shape[:2]\n",
    "            gray = cv2.cvtColor(np.asarray(pages_images[i]), cv2.COLOR_BGR2GRAY)\n",
    "            denoise = cv2.fastNlMeansDenoising(gray, h = 3, templateWindowSize = 7, searchWindowSize = 21)\n",
    "            thresh = cv2.threshold(denoise, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "            # morph open to remove noise and invert again\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))\n",
    "            opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations = 1)\n",
    "            invert = 255 - opening\n",
    "\n",
    "            # determine if rotation is required\n",
    "            invert, blank_page_indicator = rotation_determination(invert = invert)\n",
    "\n",
    "            if blank_page_indicator == \"Y\":\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                # read the entire page and convert from dictionary to df\n",
    "                d = pytesseract.image_to_data(invert, output_type = Output.DICT)\n",
    "                d_df = pd.DataFrame.from_dict(d)\n",
    "                d_df = d_df.loc[d_df['conf'] > -1].copy()\n",
    "                d_df['page'] = i + 1\n",
    "                pages_tesseract.append(d_df)\n",
    "                # print(f\"Page {i+1} converted.\")\n",
    "\n",
    "    try:\n",
    "        pages_tesseract_df = pd.concat(pages_tesseract)\n",
    "    except:\n",
    "        try:\n",
    "            pages_tesseract_df = pages_tesseract[0]\n",
    "        except:\n",
    "            print(\"No pages\")\n",
    "            return None, None\n",
    "\n",
    "    # remove unwanted characters and white space\n",
    "    for uc in unwanted_characters:\n",
    "        pages_tesseract_df['text'] = pages_tesseract_df['text'].replace(uc, ' ')\n",
    "\n",
    "    pages_tesseract_df['text'] = pages_tesseract_df['text'].str.strip()\n",
    "    pages_tesseract_df = pages_tesseract_df.loc[pages_tesseract_df['text'] != ''].copy()\n",
    "\n",
    "    # reset index\n",
    "    pages_tesseract_df.reset_index(inplace = True, drop = True)\n",
    "\n",
    "    # create a window of trailing texts\n",
    "    pages_tesseract_df['text2'] = pages_tesseract_df['text'].shift(-1)\n",
    "    pages_tesseract_df['text3'] = pages_tesseract_df['text'].shift(-2)\n",
    "    pages_tesseract_df['text4'] = pages_tesseract_df['text'].shift(-3)\n",
    "    pages_tesseract_df.fillna('', inplace = True)\n",
    "    pages_tesseract_df['trailing_text'] = pages_tesseract_df['text'] + \" \" + pages_tesseract_df['text2'] + \" \" + pages_tesseract_df['text3'] + \" \" + pages_tesseract_df['text4']\n",
    "    pages_tesseract_df['date_text'] = pages_tesseract_df['text'] + \" \" + pages_tesseract_df['text2'] + \" \" + pages_tesseract_df['text3']\n",
    "\n",
    "    # use window to detect dates\n",
    "    date_indices = []\n",
    "    \n",
    "    for m in months_of_year:\n",
    "        matching_index = pages_tesseract_df.index[pages_tesseract_df['date_text'].str.contains(fr'[0-9]\\s{m}\\s[0-9]', regex = True, case = True)]\n",
    "        for i in range(len(matching_index)):\n",
    "            date_indices.append(matching_index[i])\n",
    "    \n",
    "    date_entries = pages_tesseract_df.filter(items = date_indices, axis = 0)\n",
    "        \n",
    "    # use window to detect the opening phrase and indices.\n",
    "    # from indices, obtain coordinates for bounding box\n",
    "    opening_indices = []\n",
    "    closing_indices = []\n",
    "\n",
    "    ## get opening\n",
    "    for t in opening_phrases:\n",
    "        matching_index = pages_tesseract_df.index[pages_tesseract_df['trailing_text'].str.contains(t)].tolist()\n",
    "        for i in range(len(matching_index)):\n",
    "            opening_indices.append(matching_index[i])\n",
    "\n",
    "    opening_entries = pages_tesseract_df.filter(items = opening_indices, axis = 0)\n",
    "\n",
    "    ## get closing\n",
    "    for c in closing_phrases:\n",
    "        matching_index = pages_tesseract_df.index[pages_tesseract_df['trailing_text'].str.contains(c)].tolist()\n",
    "        #matching_index = pages_tesseract_df.index[pages_tesseract_df['text'].str.contains(c)].tolist()\n",
    "        for i in range(len(matching_index)):\n",
    "            closing_indices.append(matching_index[i])\n",
    "\n",
    "    closing_entries = pages_tesseract_df.filter(items = closing_indices, axis = 0)\n",
    "\n",
    "    # based on opening and closing indices, get the coordinates of the bounding boxes to be selected\n",
    "    ## primero, determine the number of pages this involves using the first and last entries\n",
    "    try:\n",
    "        starting_page = opening_entries.head(n = 1)['page'].tolist()[0]\n",
    "    except:\n",
    "        print(\"DP DC Clause cannot be detected.\")\n",
    "        return None, None\n",
    "    \n",
    "    try:\n",
    "        ending_page = closing_entries.tail(n = 1)['page'].tolist()[0]\n",
    "    except:\n",
    "        print(\"Cannot find closing indicator.\")\n",
    "        return None, None\n",
    "    \n",
    "    ## segundo a: if starting page is not the same as ending, determine the number of pages it crosses\n",
    "    ## segundo b: take the starting page first\n",
    "    ## segundo c: then determine if there are any intermediate complete pages\n",
    "\n",
    "    ### coordinates of bounding box = (x1, y1), (x2, y2) where n1 are the top-left and n2 are bottom right\n",
    "    ### x1 will always be 0 and x2 will always be the max width of the image\n",
    "    ### if it spills across multiple pages, the starting page's y2 will always be the bottom of the page\n",
    "\n",
    "    x1 = 0\n",
    "    x2 = np.asarray(pages_images[starting_page - 1]).shape[1]\n",
    "\n",
    "    if starting_page != ending_page:\n",
    "\n",
    "        ##### Determine if starting page needs to be rotated, get the angle and apply thru out\n",
    "        starting_page_image = np.asarray(pages_images[starting_page - 1])\n",
    "        rotation_results = pytesseract.image_to_osd(starting_page_image, output_type = pytesseract.Output.DICT)\n",
    "\n",
    "        if rotation_results[\"orientation\"] == 270:\n",
    "            starting_page_image = rotation(rotation_results[\"orientation\"],\n",
    "                                            width_center = width/3, height_center = height/2,\n",
    "                                            width = width, height = height, invert = starting_page_image)\n",
    "\n",
    "        elif (rotation_results['orientation'] > 0) & (rotation_results['orientation'] < 270):\n",
    "            starting_page_image = rotation(rotation_results[\"orientation\"],\n",
    "                                            width_center = width/2, height_center = height/2,\n",
    "                                            width = width, height = height, invert = starting_page_image)\n",
    "        else:\n",
    "            starting_page_image = starting_page_image\n",
    "\n",
    "        #### get starting page\n",
    "        starting_page_y1 = opening_entries.head(n = 1)['top'].tolist()[0]\n",
    "        starting_page_y2 = starting_page_image.shape[0]\n",
    "\n",
    "        starting_page_crop = starting_page_image[starting_page_y1:starting_page_y2, x1:x2]\n",
    "\n",
    "        #### get intermediate page\n",
    "        n_pages = ending_page - starting_page + 1\n",
    "        if n_pages == 3:\n",
    "\n",
    "            ##### Determine if intermediate page needs to be rotated\n",
    "            intermediate_page = np.asarray(pages_images[starting_page])\n",
    "\n",
    "            if rotation_results[\"orientation\"] == 270:\n",
    "                intermediate_page = rotation(rotation_results[\"orientation\"],\n",
    "                                            width_center = width/3, height_center = height/2,\n",
    "                                            width = width, height = height, invert = intermediate_page)\n",
    "\n",
    "            elif (rotation_results['orientation'] > 0) & (rotation_results['orientation'] < 270):\n",
    "                intermediate_page = rotation(rotation_results[\"orientation\"],\n",
    "                                            width_center = width/2, height_center = height/2,\n",
    "                                            width = width, height = height, invert = intermediate_page)\n",
    "            else:\n",
    "                intermediate_page = intermediate_page\n",
    "\n",
    "        elif n_pages == 4:\n",
    "\n",
    "            ##### Determine if intermediate page needs to be rotated\n",
    "            intermediate_page = np.asarray(pages_images[starting_page])\n",
    "\n",
    "            if rotation_results[\"orientation\"] == 270:\n",
    "                intermediate_page = rotation(rotation_results[\"orientation\"],\n",
    "                                            width_center = width/3, height_center = height/2,\n",
    "                                            width = width, height = height, invert = intermediate_page)\n",
    "\n",
    "            elif (rotation_results['orientation'] > 0) & (rotation_results['orientation'] < 270):\n",
    "                intermediate_page = rotation(rotation_results[\"orientation\"],\n",
    "                                            width_center = width/2, height_center = height/2,\n",
    "                                            width = width, height = height, invert = intermediate_page)\n",
    "            else:\n",
    "                intermediate_page = intermediate_page\n",
    "\n",
    "            ##### Determine if intermediate page needs to be rotated\n",
    "            intermediate_page2 = np.asarray(pages_images[starting_page + 1])\n",
    "\n",
    "            if rotation_results[\"orientation\"] == 270:\n",
    "                intermediate_page2 = rotation(rotation_results[\"orientation\"],\n",
    "                                            width_center = width/3, height_center = height/2,\n",
    "                                            width = width, height = height, invert = intermediate_page2)\n",
    "\n",
    "            elif (rotation_results['orientation'] > 0) & (rotation_results['orientation'] < 270):\n",
    "                intermediate_page2 = rotation(rotation_results[\"orientation\"],\n",
    "                                            width_center = width/2, height_center = height/2,\n",
    "                                            width = width, height = height, invert = intermediate_page2)\n",
    "            else:\n",
    "                intermediate_page2 = intermediate_page2\n",
    "\n",
    "            intermediate_page = cv2.vconcat([intermediate_page, intermediate_page2])\n",
    "\n",
    "        elif n_pages > 4:    \n",
    "\n",
    "            ##### Determine if intermediate page needs to be rotated\n",
    "            intermediate_page = np.asarray(pages_images[starting_page])\n",
    "\n",
    "            if rotation_results[\"orientation\"] == 270:\n",
    "                intermediate_page = rotation(rotation_results[\"orientation\"],\n",
    "                                            width_center = width/3, height_center = height/2,\n",
    "                                            width = width, height = height, invert = intermediate_page)\n",
    "\n",
    "            elif (rotation_results['orientation'] > 0) & (rotation_results['orientation'] < 270):\n",
    "                intermediate_page = rotation(rotation_results[\"orientation\"],\n",
    "                                            width_center = width/2, height_center = height/2,\n",
    "                                            width = width, height = height, invert = intermediate_page)\n",
    "            else:\n",
    "                intermediate_page = intermediate_page\n",
    "\n",
    "            ##### Determine if intermediate page needs to be rotated\n",
    "            intermediate_page2 = np.asarray(pages_images[starting_page + 1])\n",
    "\n",
    "            if rotation_results[\"orientation\"] == 270:\n",
    "                intermediate_page2 = rotation(rotation_results[\"orientation\"],\n",
    "                                            width_center = width/3, height_center = height/2,\n",
    "                                            width = width, height = height, invert = intermediate_page2)\n",
    "\n",
    "            elif (rotation_results['orientation'] > 0) & (rotation_results['orientation'] < 270):\n",
    "                intermediate_page2 = rotation(rotation_results[\"orientation\"],\n",
    "                                            width_center = width/2, height_center = height/2,\n",
    "                                            width = width, height = height, invert = intermediate_page2)\n",
    "            else:\n",
    "                intermediate_page2 = intermediate_page2\n",
    "\n",
    "            intermediate_page = cv2.vconcat([intermediate_page, intermediate_page2])\n",
    "\n",
    "            counter = starting_page + 1\n",
    "            for i in range(n_pages - 4):\n",
    "\n",
    "                ##### Determine if other intermediate page needs to be rotated\n",
    "                intermediate_page_i = np.asarray(pages_images[counter + i])\n",
    "\n",
    "                if rotation_results[\"orientation\"] == 270:\n",
    "                    intermediate_page_i = rotation(rotation_results[\"orientation\"],\n",
    "                                                width_center = width/3, height_center = height/2,\n",
    "                                                width = width, height = height, invert = intermediate_page_i)\n",
    "\n",
    "                elif (rotation_results['orientation'] > 0) & (rotation_results['orientation'] < 270):\n",
    "                    intermediate_page_i = rotation(rotation_results[\"orientation\"],\n",
    "                                                width_center = width/2, height_center = height/2,\n",
    "                                                width = width, height = height, invert = intermediate_page_i)\n",
    "                else:\n",
    "                    intermediate_page_i = intermediate_page_i\n",
    "\n",
    "                intermediate_page = cv2.vconcat([intermediate_page, intermediate_page_i])\n",
    "\n",
    "        #### get closing page\n",
    "        #### the top of it will always be top of the page\n",
    "        closing_page_y1 = 0\n",
    "        closing_page_y2 = closing_entries.tail(n = 1)['top'].tolist()[0] + closing_entries.tail(n = 1)['height'].tolist()[0]\n",
    "        closing_page = np.asarray(pages_images[ending_page - 1])\n",
    "        if rotation_results[\"orientation\"] == 270:\n",
    "            closing_page = rotation(rotation_results[\"orientation\"],\n",
    "                                        width_center = width/3, height_center = height/2,\n",
    "                                        width = width, height = height, invert = closing_page)\n",
    "\n",
    "        elif (rotation_results['orientation'] > 0) & (rotation_results['orientation'] < 270):\n",
    "            closing_page = rotation(rotation_results[\"orientation\"],\n",
    "                                    width_center = width/2, height_center = height/2,\n",
    "                                    width = width, height = height, invert = closing_page)\n",
    "        else:\n",
    "            closing_page = closing_page\n",
    "\n",
    "        closing_page_crop = closing_page[closing_page_y1:closing_page_y2, x1:x2]\n",
    "\n",
    "        if n_pages > 2:\n",
    "            final_image = cv2.vconcat([starting_page_crop, intermediate_page, closing_page_crop])\n",
    "        else:\n",
    "            final_image = cv2.vconcat([starting_page_crop, closing_page_crop])\n",
    "\n",
    "    else:\n",
    "        y1 = opening_entries.head(n = 1)['top'].tolist()[0]\n",
    "        y2 = closing_entries.tail(n = 1)['top'].tolist()[0] + closing_entries.tail(n = 1)['height'].tolist()[0]\n",
    "\n",
    "        final_image = np.asarray(pages_images[starting_page - 1])\n",
    "\n",
    "        # placeholder test to see whether there is a need to rotate or not\n",
    "        rotation_results = pytesseract.image_to_osd(final_image, output_type = pytesseract.Output.DICT)\n",
    "        if rotation_results[\"orientation\"] == 270:\n",
    "            final_image = rotation(angle = rotation_results[\"orientation\"],\n",
    "                                    width_center = width/3, height_center = height/2,\n",
    "                                    width = width, height = height, invert = final_image)\n",
    "\n",
    "        elif (rotation_results['orientation'] > 0) & (rotation_results['orientation'] < 270):\n",
    "            final_image = rotation(angle = rotation_results[\"orientation\"],\n",
    "                                    width_center = width/2, height_center = height/2,\n",
    "                                    width = width, height = height, invert = final_image)\n",
    "\n",
    "\n",
    "        final_image = final_image[y1:y2, x1:x2]\n",
    "\n",
    "    ## tercero: get text\n",
    "    starting_index = opening_entries.index[0]\n",
    "    closing_index = closing_entries.index[len(closing_entries.index) - 1]\n",
    "    condition = \" \".join(pages_tesseract_df.iloc[starting_index:(closing_index + 1), 11].tolist())\n",
    "    condition = clause_shortener(condition)\n",
    "    \n",
    "    dates = \" | \".join(date_entries.date_text.tolist())\n",
    "    \n",
    "    ## cuarto: imprimir\n",
    "    \n",
    "    return condition, final_image, dates\n",
    "    \n",
    "    #plt.subplot(111), plt.imshow(final_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "971231ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0902c282800788e6.pdf\n",
      "Image saved for 0902c282800788e6.pdf\n",
      "0902c282800788e6.pdf extraction complete.\n",
      "0902c28280078b59.pdf\n",
      "Image saved for 0902c28280078b59.pdf\n",
      "0902c28280078b59.pdf extraction complete.\n",
      "0902c28280078cd9.pdf\n",
      "Image saved for 0902c28280078cd9.pdf\n",
      "0902c28280078cd9.pdf extraction complete.\n",
      "0902c2828007d463.pdf\n",
      "Image saved for 0902c2828007d463.pdf\n",
      "0902c2828007d463.pdf extraction complete.\n",
      "0902c2828007da07.pdf\n",
      "Image saved for 0902c2828007da07.pdf\n",
      "0902c2828007da07.pdf extraction complete.\n",
      "0902c2828007e989.pdf\n",
      "Image saved for 0902c2828007e989.pdf\n",
      "0902c2828007e989.pdf extraction complete.\n",
      "0902c2828007ef26.pdf\n",
      "Image saved for 0902c2828007ef26.pdf\n",
      "0902c2828007ef26.pdf extraction complete.\n",
      "0902c2828007ef27.pdf\n",
      "Image saved for 0902c2828007ef27.pdf\n",
      "0902c2828007ef27.pdf extraction complete.\n",
      "0902c2828011f900.pdf\n",
      "Image saved for 0902c2828011f900.pdf\n",
      "0902c2828011f900.pdf extraction complete.\n",
      "0902c28280316b07.pdf\n",
      "Image saved for 0902c28280316b07.pdf\n",
      "0902c28280316b07.pdf extraction complete.\n",
      "0902c28280515be0.pdf\n",
      "Image saved for 0902c28280515be0.pdf\n",
      "0902c28280515be0.pdf extraction complete.\n",
      "0902c28280518e14.pdf\n",
      "Image saved for 0902c28280518e14.pdf\n",
      "0902c28280518e14.pdf extraction complete.\n",
      "0902c28280649bfe.pdf\n",
      "Image saved for 0902c28280649bfe.pdf\n",
      "0902c28280649bfe.pdf extraction complete.\n",
      "0902c28280649c00.pdf\n",
      "Image saved for 0902c28280649c00.pdf\n",
      "0902c28280649c00.pdf extraction complete.\n",
      "0902c2828064dda4.pdf\n",
      "Image saved for 0902c2828064dda4.pdf\n",
      "0902c2828064dda4.pdf extraction complete.\n",
      "0902c28280663c6f.pdf\n",
      "Image saved for 0902c28280663c6f.pdf\n",
      "0902c28280663c6f.pdf extraction complete.\n",
      "0902c28280710976.pdf\n",
      "Image saved for 0902c28280710976.pdf\n",
      "0902c28280710976.pdf extraction complete.\n",
      "0902c2828071b620.pdf\n",
      "Image saved for 0902c2828071b620.pdf\n",
      "0902c2828071b620.pdf extraction complete.\n",
      "0902c2828071eb23.pdf\n",
      "Image saved for 0902c2828071eb23.pdf\n",
      "0902c2828071eb23.pdf extraction complete.\n",
      "0902c2828071ef63.pdf\n",
      "Image saved for 0902c2828071ef63.pdf\n",
      "0902c2828071ef63.pdf extraction complete.\n",
      "0902c28280728cf5.pdf\n",
      "Image saved for 0902c28280728cf5.pdf\n",
      "0902c28280728cf5.pdf extraction complete.\n",
      "0902c282807506f6.pdf\n",
      "Image saved for 0902c282807506f6.pdf\n",
      "0902c282807506f6.pdf extraction complete.\n",
      "0902c2828076aeb5.pdf\n",
      "Image saved for 0902c2828076aeb5.pdf\n",
      "0902c2828076aeb5.pdf extraction complete.\n",
      "0902c2828076cf58.pdf\n",
      "Image saved for 0902c2828076cf58.pdf\n",
      "0902c2828076cf58.pdf extraction complete.\n",
      "0902c28280782f11.pdf\n",
      "Image saved for 0902c28280782f11.pdf\n",
      "0902c28280782f11.pdf extraction complete.\n",
      "0902c2828078620e.pdf\n",
      "Image saved for 0902c2828078620e.pdf\n",
      "0902c2828078620e.pdf extraction complete.\n",
      "0902c28280790e7b.pdf\n",
      "Image saved for 0902c28280790e7b.pdf\n",
      "0902c28280790e7b.pdf extraction complete.\n",
      "0902c2828079c32c.pdf\n",
      "Image saved for 0902c2828079c32c.pdf\n",
      "0902c2828079c32c.pdf extraction complete.\n",
      "0902c2828081ee31.pdf\n",
      "Image saved for 0902c2828081ee31.pdf\n",
      "0902c2828081ee31.pdf extraction complete.\n",
      "Elapsed Time: 11.48 minutes for 29 files.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "dms_record_list = []\n",
    "condition_list = []\n",
    "dates_list = []\n",
    "\n",
    "for file in pdf_files:\n",
    "    print(file)\n",
    "    condition, image, dates = dp_dc_extraction(file, pass_one = False)\n",
    "    dms_record_list.append(file)\n",
    "    condition_list.append(condition)\n",
    "    dates_list.append(dates)\n",
    "    try:\n",
    "        cv2.imwrite(file.split('.')[0] + '_cropped.jpg', image)\n",
    "        print(\"Image saved for \" + file)\n",
    "    except:\n",
    "        print(\"No image for \" + file)\n",
    "    print(file + \" extraction complete.\")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "time_required = (end_time - start_time)/60\n",
    "\n",
    "print(\"Elapsed Time: \" + str(round(time_required,2)) + \" minutes for \" + str(len(pdf_files)) + \" files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "640ee3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_second_pass = pd.DataFrame({\"Record\": dms_record_list,\n",
    "                                       \"Condition\":condition_list})\n",
    "results_df_second_pass.to_csv('pdf_extraction_pass_two.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50db1e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_first_pass = pd.DataFrame({\"Record\": dms_record_list,\n",
    "                           \"Condition\":condition_list})\n",
    "results_df_first_pass.to_csv('pdf_extraction.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b391796a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_df_third_pass = pd.DataFrame({\"Record\": dms_record_list,\n",
    "                                       \"Condition\":condition_list,\n",
    "                                      \"Dates\": dates_list})\n",
    "results_df_third_pass.to_csv('pdf_extraction_pass_three.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f85730",
   "metadata": {},
   "source": [
    "#### RoBERTa Q&A Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717a9fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf_hub_download(repo_id=\"deepset/tinyroberta-squad2\", filename=\"config.json\", cache_dir= r\"C:\\Users\\LPD-GS-User\\Documents\\Text_Recognition\\tiny_roberta\")\n",
    "config = AutoConfig.from_pretrained(\"C:\\\\Users\\\\<INSERT_USER_PATH>\\\\tiny_roberta\\\\models--deepset--tinyroberta-squad2\\\\snapshots\\\\20891f44e15bf4a3caf0429fd9319f2632839125\\\\config.json\")\n",
    "\n",
    "# load model\n",
    "model_name = \"deepset/tinyroberta-squad2\"\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec39315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "expiry = []\n",
    "\n",
    "\n",
    "questions_list = ['What is the expiry date?']\n",
    "\n",
    "\n",
    "nlp = pipeline('question-answering', model=model, tokenizer=tokenizer)\n",
    "\n",
    "def QnA(questions_list = questions_list, expiry = expiry, conditions = conditions):\n",
    "    \n",
    "    for c in conditions:\n",
    "        answers = []\n",
    "        try:\n",
    "            np.isnan(c)\n",
    "            for i in range(4): answers.append(np.nan)\n",
    "        except:\n",
    "            for q in questions_list:\n",
    "                QA_input = {\n",
    "                    'question': q,\n",
    "                    'context': c\n",
    "                    }\n",
    "                res = nlp(QA_input)\n",
    "                res_df = pd.DataFrame.from_dict(data = res, orient = 'index').reset_index()\n",
    "                if float(res_df.iloc[0,1]) < 0.2:\n",
    "                    answer = ''\n",
    "                else:\n",
    "                    answer = res_df.iloc[3,1]\n",
    "                answers.append(answer)\n",
    "        expiry.append(answers[0])\n",
    "\n",
    "    return expiry\n",
    "        \n",
    "expiry = QnA()    \n",
    "\n",
    "supp_df = {'Expiry Date': expiry}\n",
    "supp_df = pd.DataFrame(supp_df)\n",
    "\n",
    "pass_one_csv_enhanced = pass_one_csv.reset_index(drop = True).join(supp_df.reset_index(drop = True))\n",
    "pass_one_csv_enhanced.to_csv(r'C:\\Users\\<INSERT_USER_PATH>\\pdf_extraction_pass_one_enhanced.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "opencvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.844px",
    "left": "1511px",
    "right": "20px",
    "top": "109px",
    "width": "346px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
